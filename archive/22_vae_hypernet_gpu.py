#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
22_vae_hypernet_gpu.py - VAE + HyperNet (GPUå¹¶è¡Œç‰ˆæœ¬)
=====================================================
æ ¸å¿ƒæ€è·¯ï¼š
1. VAE: å¤§é‡æ•°æ®å¢å¼º (100å€+)
2. HyperNet: æ¨¡ä»¿RFçš„ç»“æ„
   - å¤šä¸ªå­ç½‘ç»œ (ç±»ä¼¼å¤šæ£µæ ‘)
   - æ¯ä¸ªå­ç½‘ç»œéšæœºé€‰æ‹©ç‰¹å¾å­é›† (ç±»ä¼¼RFçš„ç‰¹å¾bagging)
   - æŠ•ç¥¨é›†æˆ

GPUå¹¶è¡Œ: å¤šGPU + æ‰¹é‡å¤„ç†å¤šä¸ªfold

è¿è¡Œ: python 22_vae_hypernet_gpu.py
"""

import os
import sys
import json
import time
import logging
import warnings
from datetime import datetime
from itertools import combinations
from pathlib import Path
from concurrent.futures import ProcessPoolExecutor, as_completed

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

warnings.filterwarnings('ignore')

SCRIPT_DIR = Path(__file__).parent
LOG_DIR = SCRIPT_DIR / 'logs'
OUTPUT_DIR = SCRIPT_DIR / 'output'
LOG_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)

# GPUé…ç½®
NUM_GPUS = 6
FOLDS_PER_GPU = 20  # æ¯ä¸ªGPUåŒæ—¶å¤„ç†çš„foldæ•°


class VAE(nn.Module):
    """å˜åˆ†è‡ªç¼–ç å™¨ - ç”¨äºæ•°æ®å¢å¼º"""
    def __init__(self, input_dim, hidden_dim=32, latent_dim=8):
        super(VAE, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.LeakyReLU(0.2),
            nn.BatchNorm1d(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.LeakyReLU(0.2),
        )
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)
        self.fc_var = nn.Linear(hidden_dim, latent_dim)
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.LeakyReLU(0.2),
            nn.BatchNorm1d(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim),
            nn.LeakyReLU(0.2),
            nn.Linear(hidden_dim, input_dim),
        )
    
    def encode(self, x):
        h = self.encoder(x)
        return self.fc_mu(h), self.fc_var(h)
    
    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        return self.decoder(z)
    
    def forward(self, x):
        mu, log_var = self.encode(x)
        z = self.reparameterize(mu, log_var)
        return self.decode(z), mu, log_var


class SubNetwork(nn.Module):
    """å­ç½‘ç»œ - ç±»ä¼¼RFä¸­çš„ä¸€æ£µæ ‘"""
    def __init__(self, input_dim, hidden_dim=16, n_classes=2, dropout=0.3):
        super(SubNetwork, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, n_classes),
        )
    
    def forward(self, x):
        return self.net(x)


class HyperNetEnsemble(nn.Module):
    """
    HyperNeté›†æˆ - æ¨¡ä»¿Random Forestç»“æ„
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    1. å¤šä¸ªå­ç½‘ç»œ (ç±»ä¼¼å¤šæ£µå†³ç­–æ ‘)
    2. æ¯ä¸ªå­ç½‘ç»œä½¿ç”¨ç‰¹å¾å­é›† (ç±»ä¼¼RFçš„ç‰¹å¾bagging)
    3. Bootstrapé‡‡æ ·è®­ç»ƒæ•°æ® (ç±»ä¼¼RFçš„æ ·æœ¬bagging)
    4. æŠ•ç¥¨é›†æˆé¢„æµ‹
    """
    def __init__(self, input_dim, n_classes=2, n_estimators=50, 
                 max_features='sqrt', hidden_dim=16, dropout=0.3):
        super(HyperNetEnsemble, self).__init__()
        
        self.input_dim = input_dim
        self.n_classes = n_classes
        self.n_estimators = n_estimators
        
        # è®¡ç®—æ¯ä¸ªå­ç½‘ç»œä½¿ç”¨çš„ç‰¹å¾æ•°
        if max_features == 'sqrt':
            self.n_features = max(1, int(np.sqrt(input_dim)))
        elif max_features == 'log2':
            self.n_features = max(1, int(np.log2(input_dim)))
        else:
            self.n_features = input_dim
        
        # ä¸ºæ¯ä¸ªå­ç½‘ç»œéšæœºé€‰æ‹©ç‰¹å¾ç´¢å¼•
        self.feature_indices = []
        for _ in range(n_estimators):
            indices = np.random.choice(input_dim, self.n_features, replace=False)
            self.feature_indices.append(indices)
        
        # åˆ›å»ºå­ç½‘ç»œ
        self.sub_networks = nn.ModuleList([
            SubNetwork(self.n_features, hidden_dim, n_classes, dropout)
            for _ in range(n_estimators)
        ])
    
    def forward(self, x):
        """å‰å‘ä¼ æ’­ - æ‰€æœ‰å­ç½‘ç»œçš„å¹³å‡è¾“å‡º"""
        outputs = []
        for i, subnet in enumerate(self.sub_networks):
            # é€‰æ‹©è¯¥å­ç½‘ç»œå¯¹åº”çš„ç‰¹å¾
            x_subset = x[:, self.feature_indices[i]]
            outputs.append(subnet(x_subset))
        
        # å¹³å‡æ‰€æœ‰å­ç½‘ç»œçš„è¾“å‡º (è½¯æŠ•ç¥¨)
        return torch.stack(outputs).mean(dim=0)
    
    def predict_with_vote(self, x):
        """ç¡¬æŠ•ç¥¨é¢„æµ‹"""
        votes = []
        for i, subnet in enumerate(self.sub_networks):
            x_subset = x[:, self.feature_indices[i]]
            pred = subnet(x_subset).argmax(dim=1)
            votes.append(pred)
        
        # æŠ•ç¥¨
        votes = torch.stack(votes, dim=0)  # [n_estimators, batch_size]
        final_pred = []
        for j in range(x.shape[0]):
            vote_counts = torch.bincount(votes[:, j], minlength=self.n_classes)
            final_pred.append(vote_counts.argmax().item())
        return final_pred


def vae_augment_gpu(X_train, y_train, device, aug_factor=50):
    """
    GPUä¸Šçš„VAEæ•°æ®å¢å¼º
    
    å¢å¼ºç­–ç•¥ï¼š
    1. åŸå§‹-é‡å»ºæ’å€¼
    2. æ½œåœ¨ç©ºé—´é‡‡æ ·
    3. é«˜æ–¯å™ªå£°å¢å¼º
    4. Mixupå¢å¼º
    """
    input_dim = X_train.shape[1]
    
    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_train)
    
    X_aug_list = [X_scaled]
    y_aug_list = [y_train]
    
    # å¯¹æ¯ä¸ªç±»åˆ«åˆ†åˆ«è®­ç»ƒVAE
    for cls in np.unique(y_train):
        X_cls = X_scaled[y_train == cls]
        if len(X_cls) < 2:
            continue
        
        # è®­ç»ƒVAE
        vae = VAE(input_dim, hidden_dim=32, latent_dim=8).to(device)
        optimizer = optim.Adam(vae.parameters(), lr=0.005)
        X_tensor = torch.FloatTensor(X_cls).to(device)
        
        vae.train()
        for epoch in range(100):
            optimizer.zero_grad()
            recon, mu, log_var = vae(X_tensor)
            
            # é‡å»ºæŸå¤± + KLæ•£åº¦
            recon_loss = nn.MSELoss()(recon, X_tensor)
            kl_loss = -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())
            loss = recon_loss + 0.01 * kl_loss
            
            loss.backward()
            optimizer.step()
        
        vae.eval()
        with torch.no_grad():
            # 1. åŸå§‹-é‡å»ºæ’å€¼ (ä¸»è¦å¢å¼ºæ–¹å¼)
            recon = vae(X_tensor)[0].cpu().numpy()
            for alpha in np.linspace(0.1, 0.9, aug_factor // 5):
                interpolated = alpha * X_cls + (1 - alpha) * recon
                X_aug_list.append(interpolated)
                y_aug_list.append(np.full(len(X_cls), cls))
            
            # 2. æ½œåœ¨ç©ºé—´é‡‡æ ·
            mu, log_var = vae.encode(X_tensor)
            for _ in range(aug_factor // 5):
                # åœ¨æ½œåœ¨ç©ºé—´æ·»åŠ å™ªå£°
                z = vae.reparameterize(mu, log_var * 0.5)  # å‡å°æ–¹å·®
                new_samples = vae.decode(z).cpu().numpy()
                X_aug_list.append(new_samples)
                y_aug_list.append(np.full(len(X_cls), cls))
            
            # 3. é«˜æ–¯å™ªå£°å¢å¼º
            for noise_std in [0.05, 0.1, 0.15, 0.2]:
                noisy = X_cls + np.random.randn(*X_cls.shape) * noise_std
                X_aug_list.append(noisy)
                y_aug_list.append(np.full(len(X_cls), cls))
            
            # 4. Mixup (åŒç±»å†…éƒ¨)
            if len(X_cls) >= 2:
                for _ in range(aug_factor // 10):
                    idx1, idx2 = np.random.choice(len(X_cls), 2, replace=False)
                    lam = np.random.beta(0.4, 0.4)
                    mixed = lam * X_cls[idx1] + (1 - lam) * X_cls[idx2]
                    X_aug_list.append(mixed.reshape(1, -1))
                    y_aug_list.append(np.array([cls]))
    
    return np.vstack(X_aug_list), np.hstack(y_aug_list), scaler


def train_hypernet(X_train, y_train, device, n_estimators=50, epochs=150):
    """è®­ç»ƒHyperNeté›†æˆ"""
    input_dim = X_train.shape[1]
    n_classes = len(np.unique(y_train))
    
    model = HyperNetEnsemble(
        input_dim=input_dim,
        n_classes=n_classes,
        n_estimators=n_estimators,
        max_features='sqrt' if input_dim > 2 else None,
        hidden_dim=16,
        dropout=0.3
    ).to(device)
    
    optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.01)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)
    criterion = nn.CrossEntropyLoss()
    
    X_tensor = torch.FloatTensor(X_train).to(device)
    y_tensor = torch.LongTensor(y_train).to(device)
    
    model.train()
    for epoch in range(epochs):
        # Bootstrapé‡‡æ · (ç±»ä¼¼RF)
        bootstrap_idx = np.random.choice(len(X_train), len(X_train), replace=True)
        X_batch = X_tensor[bootstrap_idx]
        y_batch = y_tensor[bootstrap_idx]
        
        optimizer.zero_grad()
        outputs = model(X_batch)
        loss = criterion(outputs, y_batch)
        loss.backward()
        optimizer.step()
        scheduler.step()
    
    return model


def process_fold_batch_gpu(args):
    """GPUä¸Šæ‰¹é‡å¤„ç†å¤šä¸ªfold"""
    gpu_id, fold_batch, X_all, y_all = args
    device = torch.device(f'cuda:{gpu_id}' if torch.cuda.is_available() else 'cpu')
    
    results = []
    for fold_idx, train_idx, test_idx in fold_batch:
        X_train, y_train = X_all[train_idx], y_all[train_idx]
        X_test, y_test = X_all[test_idx], y_all[test_idx]
        
        # VAEæ•°æ®å¢å¼º
        X_aug, y_aug, scaler = vae_augment_gpu(X_train, y_train, device, aug_factor=50)
        X_test_scaled = scaler.transform(X_test)
        
        # è®­ç»ƒHyperNet
        model = train_hypernet(X_aug, y_aug, device, n_estimators=50, epochs=100)
        
        # é¢„æµ‹
        model.eval()
        with torch.no_grad():
            X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)
            y_pred = model.predict_with_vote(X_test_tensor)
        
        results.append({
            'fold_idx': fold_idx,
            'y_true': y_test.tolist(),
            'y_pred': y_pred
        })
    
    return results


def process_fold_rf(args):
    """RFåŸºçº¿"""
    fold_idx, X_train, y_train, X_test, y_test = args
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X_train)
    X_test_s = scaler.transform(X_test)
    
    rf = RandomForestClassifier(n_estimators=100, max_depth=4, random_state=42)
    rf.fit(X_train_s, y_train)
    y_pred = rf.predict(X_test_s)
    
    return {'y_true': y_test.tolist(), 'y_pred': y_pred.tolist()}


def main():
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = LOG_DIR / f'22_vae_hypernet_gpu_{timestamp}.log'
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler(log_file, encoding='utf-8')
        ]
    )
    logger = logging.getLogger(__name__)
    
    logger.info("=" * 70)
    logger.info("22_vae_hypernet_gpu.py - VAE + HyperNet (GPUå¹¶è¡Œ)")
    logger.info("=" * 70)
    
    # æ£€æµ‹GPU
    if torch.cuda.is_available():
        n_gpus = torch.cuda.device_count()
        logger.info(f"æ£€æµ‹åˆ° {n_gpus} ä¸ªGPU")
        for i in range(n_gpus):
            logger.info(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
    else:
        logger.info("æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPU")
        n_gpus = 1
    
    # åŠ è½½æ•°æ®
    data_path = SCRIPT_DIR / 'data' / 'Data_for_Jinming.csv'
    df = pd.read_csv(data_path)
    X = df[['LAA', 'Glutamate', 'Choline', 'Sarcosine']].values.astype(np.float32)
    y = LabelEncoder().fit_transform(df['Group'].values)
    
    n_samples = len(X)
    logger.info(f"æ•°æ®: {n_samples} æ ·æœ¬, {X.shape[1]} ç‰¹å¾")
    
    # ç”Ÿæˆæ‰€æœ‰fold
    test_combos = list(combinations(range(n_samples), 2))
    n_folds = len(test_combos)
    logger.info(f"Leave-2-Out: {n_folds} folds")
    
    # å‡†å¤‡foldæ•°æ®
    fold_list = []
    for fold_idx, test_idx in enumerate(test_combos):
        test_idx = np.array(test_idx)
        train_idx = np.setdiff1d(np.arange(n_samples), test_idx)
        fold_list.append((fold_idx, train_idx, test_idx))
    
    results = {}
    
    # ========== 1. RF åŸºçº¿ ==========
    logger.info("\n[1/2] Random Forest åŸºçº¿...")
    start = time.time()
    
    rf_fold_args = [
        (i, X[train_idx], y[train_idx], X[test_idx], y[test_idx])
        for i, (fold_idx, train_idx, test_idx) in enumerate(fold_list)
    ]
    
    with ProcessPoolExecutor(max_workers=64) as executor:
        rf_results = list(executor.map(process_fold_rf, rf_fold_args))
    
    y_true_all = [item for r in rf_results for item in r['y_true']]
    y_pred_all = [item for r in rf_results for item in r['y_pred']]
    results['RF'] = accuracy_score(y_true_all, y_pred_all) * 100
    logger.info(f"   RF: {results['RF']:.2f}% ({time.time()-start:.1f}s)")
    
    # ========== 2. VAE + HyperNet (GPU) ==========
    logger.info("\n[2/2] VAE + HyperNet (GPUå¹¶è¡Œ)...")
    start = time.time()
    
    # åˆ†é…foldåˆ°ä¸åŒGPU
    use_gpus = min(n_gpus, NUM_GPUS) if torch.cuda.is_available() else 1
    folds_per_batch = FOLDS_PER_GPU
    
    # å°†foldåˆ†æˆæ‰¹æ¬¡ï¼Œåˆ†é…åˆ°ä¸åŒGPU
    gpu_tasks = []
    for gpu_id in range(use_gpus):
        gpu_folds = fold_list[gpu_id::use_gpus]  # æ¯ä¸ªGPUå¤„ç†é—´éš”çš„fold
        # å†åˆ†æˆå°æ‰¹æ¬¡
        for i in range(0, len(gpu_folds), folds_per_batch):
            batch = gpu_folds[i:i+folds_per_batch]
            gpu_tasks.append((gpu_id, batch, X, y))
    
    logger.info(f"   ä½¿ç”¨ {use_gpus} ä¸ªGPU, {len(gpu_tasks)} ä¸ªæ‰¹æ¬¡")
    
    all_hypernet_results = []
    processed = 0
    total_batches = len(gpu_tasks)
    
    # å¹¶è¡Œå¤„ç†
    with ProcessPoolExecutor(max_workers=use_gpus) as executor:
        futures = {executor.submit(process_fold_batch_gpu, task): task for task in gpu_tasks}
        
        for future in as_completed(futures):
            batch_results = future.result()
            all_hypernet_results.extend(batch_results)
            processed += 1
            if processed % 5 == 0 or processed == total_batches:
                logger.info(f"   è¿›åº¦: {processed}/{total_batches} æ‰¹æ¬¡ ({100*processed/total_batches:.1f}%)")
    
    # è®¡ç®—å‡†ç¡®ç‡
    y_true_all = [item for r in all_hypernet_results for item in r['y_true']]
    y_pred_all = [item for r in all_hypernet_results for item in r['y_pred']]
    results['VAE+HyperNet'] = accuracy_score(y_true_all, y_pred_all) * 100
    logger.info(f"   VAE+HyperNet: {results['VAE+HyperNet']:.2f}% ({time.time()-start:.1f}s)")
    
    # ========== ç»“æœ ==========
    logger.info("\n" + "=" * 70)
    logger.info("[æœ€ç»ˆç»“æœ]")
    logger.info("=" * 70)
    for name, acc in results.items():
        marker = "ğŸ†" if acc == max(results.values()) else "  "
        logger.info(f"{marker} {name:20s}: {acc:.2f}%")
    logger.info("=" * 70)
    
    # ä¿å­˜ç»“æœ
    result_file = OUTPUT_DIR / f'22_vae_hypernet_gpu_{timestamp}.json'
    with open(result_file, 'w') as f:
        json.dump(results, f, indent=2)
    logger.info(f"ä¿å­˜: {result_file}")


if __name__ == '__main__':
    main()
