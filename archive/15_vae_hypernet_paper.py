#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
15_vae_hypernet_paper.py - ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡å®ç°çš„VAE-HyperNetFusion
=================================================================
ä¸¥æ ¼æŒ‰ç…§ IEEE ICC 2026 è®ºæ–‡å®ç°ï¼š

1. VAEæ•°æ®å¢å¼ºï¼š
   - hidden_dim=512, latent_dim=20
   - epochs=50, lr=0.001, batch_size=128
   - æ’å€¼ï¼š5ä¸ªå‡åŒ€åˆ†å¸ƒçš„å†…éƒ¨ç‚¹

2. è¶…ç½‘ç»œ + ç›®æ ‡ç½‘ç»œé›†æˆï¼š
   - **ä¸€ä¸ª**è¶…ç½‘ç»œ H(z; Ï†) ç”Ÿæˆ**å¤šä¸ª**ç›®æ ‡ç½‘ç»œçš„æƒé‡
   - æ¯ä¸ªç›®æ ‡ç½‘ç»œå­¦ä¹ æ•°æ®çš„ä¸åŒ"åˆ‡ç‰‡"(descriptor z_i)
   - æœ€ç»ˆé¢„æµ‹ï¼šå¹³å‡æ‰€æœ‰ç›®æ ‡ç½‘ç»œçš„logits

å…³é”®å…¬å¼ï¼š
   Î¸_i = H(z_i; Ï†)          -- å…¬å¼3
   Å· = F(f_1(x), ..., f_m(x)) -- å…¬å¼4

è¿è¡Œ: python 15_vae_hypernet_paper.py
"""

import os
import sys
import json
import time
import logging
import warnings
import threading
from datetime import datetime
from itertools import combinations
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler
from sklearn.metrics import accuracy_score

warnings.filterwarnings('ignore')

# è·¯å¾„é…ç½®
SCRIPT_DIR = Path(__file__).parent
LOG_DIR = SCRIPT_DIR / 'logs'
OUTPUT_DIR = SCRIPT_DIR / 'output'
LOG_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)

# GPUé…ç½®
GPU_IDS = [0, 1, 2, 3, 4, 5]


# ==================== VAE - æŒ‰è®ºæ–‡å‚æ•° ====================
class VAE(nn.Module):
    """
    å˜åˆ†è‡ªç¼–ç å™¨ - ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡å‚æ•°
    è®ºæ–‡: "hidden layer of width 512 and a latent dimension of 20"
    """
    def __init__(self, input_dim, hidden_dim=512, latent_dim=20):
        super(VAE, self).__init__()
        
        # Encoder
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU()
        )
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)
        self.fc_var = nn.Linear(hidden_dim, latent_dim)
        
        # Decoder - è¾“å‡ºsigmoidåŒ¹é…min-maxå½’ä¸€åŒ–çš„[0,1]èŒƒå›´
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim),
            nn.Sigmoid()  # è®ºæ–‡: "matches the sigmoid output of the decoder"
        )
    
    def encode(self, x):
        h = self.encoder(x)
        return self.fc_mu(h), self.fc_var(h)
    
    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        return self.decoder(z)
    
    def forward(self, x):
        mu, log_var = self.encode(x)
        z = self.reparameterize(mu, log_var)
        recon = self.decode(z)
        return recon, mu, log_var


# ==================== è¶…ç½‘ç»œ - æŒ‰è®ºæ–‡è®¾è®¡ ====================
class HyperNetwork(nn.Module):
    """
    è¶…ç½‘ç»œï¼šç”Ÿæˆå¤šä¸ªç›®æ ‡ç½‘ç»œçš„æƒé‡
    è®ºæ–‡: "hypernetwork H used to generate all weights and biases for the target network"
    å…¬å¼3: Î¸_i = H(z_i; Ï†)
    
    z_i æ˜¯æè¿°ç¬¬iä¸ªç›®æ ‡ç½‘ç»œçš„descriptor
    """
    def __init__(self, descriptor_dim, hidden_dim, target_input_dim, target_hidden_dim, n_classes):
        super(HyperNetwork, self).__init__()
        
        self.target_input_dim = target_input_dim
        self.target_hidden_dim = target_hidden_dim
        self.n_classes = n_classes
        
        # è¶…ç½‘ç»œä¸»ä½“
        self.net = nn.Sequential(
            nn.Linear(descriptor_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU()
        )
        
        # ç”Ÿæˆç›®æ ‡ç½‘ç»œç¬¬ä¸€å±‚æƒé‡å’Œåç½®
        self.gen_w1 = nn.Linear(hidden_dim, target_input_dim * target_hidden_dim)
        self.gen_b1 = nn.Linear(hidden_dim, target_hidden_dim)
        
        # ç”Ÿæˆç›®æ ‡ç½‘ç»œç¬¬äºŒå±‚æƒé‡å’Œåç½®
        self.gen_w2 = nn.Linear(hidden_dim, target_hidden_dim * n_classes)
        self.gen_b2 = nn.Linear(hidden_dim, n_classes)
    
    def forward(self, descriptor):
        """
        è¾“å…¥: descriptor z_i (æè¿°ç¬¬iä¸ªç›®æ ‡ç½‘ç»œçš„ç‰¹å¾)
        è¾“å‡º: ç›®æ ‡ç½‘ç»œçš„æƒé‡ (w1, b1, w2, b2)
        """
        h = self.net(descriptor)
        
        w1 = self.gen_w1(h).view(-1, self.target_input_dim, self.target_hidden_dim)
        b1 = self.gen_b1(h)
        w2 = self.gen_w2(h).view(-1, self.target_hidden_dim, self.n_classes)
        b2 = self.gen_b2(h)
        
        return w1, b1, w2, b2


class TargetNetwork:
    """
    ç›®æ ‡ç½‘ç»œï¼šä½¿ç”¨è¶…ç½‘ç»œç”Ÿæˆçš„æƒé‡è¿›è¡Œå‰å‘ä¼ æ’­
    è®ºæ–‡: "Each target network is a compact MLP classifier with one hidden layer"
    """
    @staticmethod
    def forward(x, w1, b1, w2, b2):
        """
        x: è¾“å…¥æ•°æ® [batch, input_dim]
        w1, b1: ç¬¬ä¸€å±‚æƒé‡å’Œåç½®
        w2, b2: ç¬¬äºŒå±‚æƒé‡å’Œåç½®
        """
        # ç¬¬ä¸€å±‚
        if len(w1.shape) == 3:
            h = torch.bmm(x.unsqueeze(1), w1).squeeze(1) + b1
        else:
            h = torch.mm(x, w1) + b1
        h = torch.relu(h)
        
        # ç¬¬äºŒå±‚ï¼ˆè¾“å‡ºå±‚ï¼‰
        if len(w2.shape) == 3:
            out = torch.bmm(h.unsqueeze(1), w2).squeeze(1) + b2
        else:
            out = torch.mm(h, w2) + b2
        
        return out


class VAEHyperNetFusion:
    """
    VAE-HyperNetFusion å®Œæ•´æ¡†æ¶ - ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡
    
    1. VAEæ•°æ®å¢å¼º + æ’å€¼
    2. ä¸€ä¸ªè¶…ç½‘ç»œç”Ÿæˆå¤šä¸ªç›®æ ‡ç½‘ç»œæƒé‡
    3. ç›®æ ‡ç½‘ç»œé›†æˆé¢„æµ‹
    """
    def __init__(self, input_dim, n_classes, n_target_networks, device, config):
        self.input_dim = input_dim
        self.n_classes = n_classes
        self.n_target_networks = n_target_networks  # ç›®æ ‡ç½‘ç»œæ•°é‡ m
        self.device = device
        self.config = config
        
        # æè¿°ç¬¦ç»´åº¦ = è¾“å…¥ç»´åº¦ (æ¯ä¸ªç›®æ ‡ç½‘ç»œçœ‹åˆ°æ•°æ®çš„ä¸åŒ"è§†è§’")
        self.descriptor_dim = input_dim * 2  # ä½¿ç”¨meanå’Œstdä½œä¸ºdescriptor
        
        # è¶…ç½‘ç»œ - åªæœ‰ä¸€ä¸ªï¼ç”Ÿæˆæ‰€æœ‰ç›®æ ‡ç½‘ç»œçš„æƒé‡
        self.hypernet = HyperNetwork(
            descriptor_dim=self.descriptor_dim,
            hidden_dim=config['hyper_hidden'],
            target_input_dim=input_dim,
            target_hidden_dim=config['target_hidden'],
            n_classes=n_classes
        ).to(device)
        
        self.vae = None
        self.scaler = MinMaxScaler()  # è®ºæ–‡: "min-max normalization"
        self.std_scaler = StandardScaler()
    
    def train_vae(self, X_train):
        """
        è®­ç»ƒVAE - ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡å‚æ•°
        è®ºæ–‡: "trained for 50 epochs with Adam using lr=0.001 and batch_size=128"
        """
        # Min-maxå½’ä¸€åŒ–åˆ°[0,1]
        X_normalized = self.scaler.fit_transform(X_train)
        X_tensor = torch.FloatTensor(X_normalized).to(self.device)
        
        self.vae = VAE(
            input_dim=self.input_dim,
            hidden_dim=512,   # è®ºæ–‡å‚æ•°
            latent_dim=20     # è®ºæ–‡å‚æ•°
        ).to(self.device)
        
        optimizer = optim.Adam(self.vae.parameters(), lr=0.001)  # è®ºæ–‡å‚æ•°
        
        self.vae.train()
        batch_size = min(128, len(X_tensor))  # è®ºæ–‡: batch_size=128
        
        for epoch in range(self.config['vae_epochs']):  # è®ºæ–‡: 50 epochs
            # éšæœºæ‰“ä¹±
            perm = torch.randperm(len(X_tensor))
            
            for i in range(0, len(X_tensor), batch_size):
                batch_idx = perm[i:i+batch_size]
                batch = X_tensor[batch_idx]
                
                optimizer.zero_grad()
                recon, mu, log_var = self.vae(batch)
                
                # ç¡®ä¿åœ¨[0,1]èŒƒå›´å†…ï¼Œé¿å…BCELossé”™è¯¯
                recon = torch.clamp(recon, 1e-6, 1-1e-6)
                batch_clamped = torch.clamp(batch, 1e-6, 1-1e-6)
                
                # è®ºæ–‡: "binary cross-entropy reconstruction term with KL regularization"
                recon_loss = nn.BCELoss()(recon, batch_clamped)
                kl_loss = -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())
                
                loss = recon_loss + kl_loss
                loss.backward()
                optimizer.step()
    
    def augment_data(self, X_train, y_train):
        """
        VAEæ•°æ®å¢å¼º + æ’å€¼ - ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡
        è®ºæ–‡: "5 evenly spaced interior points on the line segment"
        å…¬å¼2: xÌ‚_Î± = Î±Â·x + (1-Î±)Â·x'
        """
        # å½’ä¸€åŒ–
        X_normalized = self.scaler.transform(X_train)
        X_tensor = torch.FloatTensor(X_normalized).to(self.device)
        
        self.vae.eval()
        with torch.no_grad():
            recon, _, _ = self.vae(X_tensor)
        
        # è®ºæ–‡: "5 evenly spaced interior points"
        # interior pointsæ„å‘³ç€ä¸åŒ…æ‹¬ç«¯ç‚¹(0å’Œ1)
        alphas = np.linspace(0, 1, 7)[1:-1]  # [0.167, 0.333, 0.5, 0.667, 0.833] 5ä¸ªå†…éƒ¨ç‚¹
        
        X_aug_list = [X_tensor]
        y_aug_list = [torch.LongTensor(y_train).to(self.device)]
        
        for alpha in alphas:
            # å…¬å¼2: æ’å€¼
            interp = alpha * X_tensor + (1 - alpha) * recon
            X_aug_list.append(interp)
            y_aug_list.append(torch.LongTensor(y_train).to(self.device))
        
        X_aug = torch.cat(X_aug_list, dim=0)
        y_aug = torch.cat(y_aug_list, dim=0)
        
        # è½¬æ¢å›åŸå§‹ç‰¹å¾ç©ºé—´
        X_aug_np = X_aug.cpu().numpy()
        X_aug_original = self.scaler.inverse_transform(X_aug_np)
        
        return X_aug_original, y_aug.cpu().numpy()
    
    def compute_descriptors(self, X_aug):
        """
        è®¡ç®—æ¯ä¸ªç›®æ ‡ç½‘ç»œçš„descriptor
        è®ºæ–‡: "z_i is a descriptor that characterizes the features or data slices"
        
        ç­–ç•¥ï¼šæ¯ä¸ªç›®æ ‡ç½‘ç»œçœ‹åˆ°æ•°æ®çš„ä¸åŒéšæœºå­é›†ï¼ˆbootstrapï¼‰
        """
        descriptors = []
        X_tensor = torch.FloatTensor(X_aug).to(self.device)
        
        for i in range(self.n_target_networks):
            # æ¯ä¸ªç›®æ ‡ç½‘ç»œä½¿ç”¨ä¸åŒçš„éšæœºå­é›†è®¡ç®—descriptor
            np.random.seed(42 + i)
            indices = np.random.choice(len(X_aug), size=len(X_aug), replace=True)  # bootstrap
            X_subset = X_tensor[indices]
            
            # descriptor = [mean, std] of the data slice
            mean = X_subset.mean(dim=0)
            std = X_subset.std(dim=0) + 1e-6
            descriptor = torch.cat([mean, std]).unsqueeze(0)
            descriptors.append(descriptor)
        
        return descriptors
    
    def train(self, X_train, y_train):
        """è®­ç»ƒå®Œæ•´çš„VAE-HyperNetFusion"""
        # 1. è®­ç»ƒVAE
        self.train_vae(X_train)
        
        # 2. æ•°æ®å¢å¼º
        X_aug, y_aug = self.augment_data(X_train, y_train)
        
        # 3. æ ‡å‡†åŒ–å¢å¼ºåçš„æ•°æ®
        X_aug_scaled = self.std_scaler.fit_transform(X_aug)
        X_tensor = torch.FloatTensor(X_aug_scaled).to(self.device)
        y_tensor = torch.LongTensor(y_aug).to(self.device)
        
        # 4. è®¡ç®—æ¯ä¸ªç›®æ ‡ç½‘ç»œçš„descriptor
        descriptors = self.compute_descriptors(X_aug_scaled)
        
        # 5. è®­ç»ƒè¶…ç½‘ç»œ
        optimizer = optim.Adam(self.hypernet.parameters(), lr=self.config['lr'], weight_decay=self.config['weight_decay'])
        criterion = nn.CrossEntropyLoss()
        
        self.hypernet.train()
        for epoch in range(self.config['epochs']):
            total_loss = 0
            
            for i, descriptor in enumerate(descriptors):
                optimizer.zero_grad()
                
                # è¶…ç½‘ç»œç”Ÿæˆç¬¬iä¸ªç›®æ ‡ç½‘ç»œçš„æƒé‡
                w1, b1, w2, b2 = self.hypernet(descriptor)
                
                # ç›®æ ‡ç½‘ç»œå‰å‘ä¼ æ’­
                outputs = TargetNetwork.forward(X_tensor, w1[0], b1[0], w2[0], b2[0])
                loss = criterion(outputs, y_tensor)
                
                loss.backward()
                optimizer.step()
                total_loss += loss.item()
    
    def predict(self, X_test):
        """
        é›†æˆé¢„æµ‹ - ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡
        è®ºæ–‡å…¬å¼4: Å· = F(f_1(x), ..., f_m(x))
        "averaging their logits before taking the final class decision"
        """
        X_scaled = self.std_scaler.transform(X_test)
        X_tensor = torch.FloatTensor(X_scaled).to(self.device)
        
        # è®¡ç®—descriptors
        descriptors = self.compute_descriptors(self.std_scaler.transform(
            self.scaler.inverse_transform(self.scaler.transform(X_test))
        ))
        
        self.hypernet.eval()
        all_logits = []
        
        with torch.no_grad():
            for descriptor in descriptors:
                # è¶…ç½‘ç»œç”Ÿæˆæƒé‡
                w1, b1, w2, b2 = self.hypernet(descriptor)
                
                # ç›®æ ‡ç½‘ç»œé¢„æµ‹
                logits = TargetNetwork.forward(X_tensor, w1[0], b1[0], w2[0], b2[0])
                all_logits.append(logits)
        
        # è®ºæ–‡: "averaging their logits"
        avg_logits = torch.stack(all_logits).mean(dim=0)
        
        # è®ºæ–‡: "values greater than 0.5 are considered as class 1"
        if self.n_classes == 2:
            probs = torch.softmax(avg_logits, dim=1)
            return (probs[:, 1] > 0.5).long().cpu().numpy()
        else:
            return avg_logits.argmax(dim=1).cpu().numpy()


class GPUWorker:
    """GPUå·¥ä½œçº¿ç¨‹"""
    def __init__(self, gpu_id, config):
        self.gpu_id = gpu_id
        self.device = torch.device(f'cuda:{gpu_id}')
        self.config = config
        self.results = []
        self.processed_count = 0
        self.lock = threading.Lock()
        self.n_threads = 16  # å¢åŠ çº¿ç¨‹æ•°åŠ é€Ÿ
    
    def process_fold(self, fold_data):
        """å¤„ç†å•ä¸ªfold"""
        fold_idx, X_train, y_train, X_test, y_test = fold_data
        
        try:
            n_classes = len(np.unique(y_train))
            
            # åˆ›å»ºVAE-HyperNetFusion
            model = VAEHyperNetFusion(
                input_dim=X_train.shape[1],
                n_classes=n_classes,
                n_target_networks=self.config['n_target_networks'],
                device=self.device,
                config=self.config
            )
            
            # è®­ç»ƒ
            model.train(X_train, y_train)
            
            # é¢„æµ‹
            y_pred = model.predict(X_test)
            
            acc = accuracy_score(y_test, y_pred)
            result = {
                'fold_idx': fold_idx,
                'accuracy': acc,
                'y_true': y_test.tolist(),
                'y_pred': y_pred.tolist(),
                'gpu_id': self.gpu_id
            }
        except Exception as e:
            result = {'fold_idx': fold_idx, 'accuracy': 0.0, 'error': str(e), 'gpu_id': self.gpu_id}
        
        with self.lock:
            self.results.append(result)
            self.processed_count += 1
        
        return result
    
    def process_batch(self, fold_batch):
        """æ‰¹å¤„ç†"""
        print(f"\n[GPU {self.gpu_id}] å¼€å§‹å¤„ç† {len(fold_batch)} ä¸ªfolds...", flush=True)
        with ThreadPoolExecutor(max_workers=self.n_threads) as executor:
            list(executor.map(self.process_fold, fold_batch))


def progress_monitor(workers, total, start_time, stop_event):
    """è¿›åº¦ç›‘æ§"""
    while not stop_event.is_set():
        current = sum(w.processed_count for w in workers)
        elapsed = time.time() - start_time
        
        if elapsed > 0 and current > 0:
            rate = current / elapsed
            eta = (total - current) / rate if rate > 0 else 0
            pct = current / total * 100
            
            all_valid = []
            for w in workers:
                all_valid.extend([r for r in w.results if 'error' not in r])
            
            if all_valid:
                all_true = [item for r in all_valid for item in r['y_true']]
                all_pred = [item for r in all_valid for item in r['y_pred']]
                total_acc = accuracy_score(all_true, all_pred) * 100
            else:
                total_acc = 0.0
            
            bar_len = 30
            filled = int(bar_len * current / total)
            bar = 'â–ˆ' * filled + 'â–‘' * (bar_len - filled)
            
            print(f'\r[{bar}] {current}/{total} ({pct:.1f}%) | {rate:.2f}/s | ETA:{eta:.0f}s | Acc:{total_acc:.2f}%', end='', flush=True)
        
        if current >= total:
            break
        
        time.sleep(0.5)
    print()


def main():
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = LOG_DIR / f'15_vae_hypernet_paper_{timestamp}.log'
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler(log_file, encoding='utf-8')
        ]
    )
    logger = logging.getLogger(__name__)
    
    logger.info("=" * 70)
    logger.info("15_vae_hypernet_paper.py - ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡å®ç°çš„VAE-HyperNetFusion")
    logger.info("=" * 70)
    
    if not torch.cuda.is_available():
        logger.error("CUDAä¸å¯ç”¨!")
        return
    
    n_gpus = torch.cuda.device_count()
    available_gpus = [i for i in GPU_IDS if i < n_gpus]
    logger.info(f"å¯ç”¨GPU: {available_gpus}")
    
    # é…ç½® - å¿«é€Ÿç‰ˆæœ¬ï¼ˆå…ˆéªŒè¯æ€è·¯ï¼‰
    config = {
        'n_target_networks': 3,   # å‡å°‘ç›®æ ‡ç½‘ç»œæ•°é‡
        'hyper_hidden': 128,      # å‡å°
        'target_hidden': 32,      # å‡å°
        'lr': 0.005,              # å¢å¤§lråŠ é€Ÿæ”¶æ•›
        'weight_decay': 0.0001,
        'epochs': 30,             # å¤§å¹…å‡å°‘
        'vae_epochs': 20,         # å¤§å¹…å‡å°‘
    }
    
    logger.info("é…ç½®ï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰:")
    logger.info(f"  VAE: hidden=512, latent=20, epochs={config['vae_epochs']}")
    logger.info(f"  æ’å€¼: 5ä¸ªå‡åŒ€åˆ†å¸ƒçš„å†…éƒ¨ç‚¹")
    logger.info(f"  ç›®æ ‡ç½‘ç»œæ•°é‡: {config['n_target_networks']}")
    logger.info(f"  è¶…ç½‘ç»œè®­ç»ƒ: epochs={config['epochs']}, lr={config['lr']}")
    
    # åŠ è½½æ•°æ®
    data_path = SCRIPT_DIR / 'data' / 'Data_for_Jinming.csv'
    df = pd.read_csv(data_path)
    feature_cols = ['LAA', 'Glutamate', 'Choline', 'Sarcosine']
    X = df[feature_cols].values.astype(np.float32)
    y_raw = df['Group'].values
    le = LabelEncoder()
    y = le.fit_transform(y_raw)
    
    n_samples = len(X)
    logger.info(f"æ•°æ®: {n_samples} æ ·æœ¬, {X.shape[1]} ç‰¹å¾")
    logger.info(f"ç±»åˆ«: {le.classes_}")
    
    # ç”Ÿæˆæ‰€æœ‰fold
    all_indices = np.arange(n_samples)
    leave_p_out = 2
    test_combos = list(combinations(all_indices, leave_p_out))
    n_folds = len(test_combos)
    
    logger.info(f"Leave-{leave_p_out}-Out: {n_folds} ä¸ª folds (è®ºæ–‡æ–¹æ³•)")
    
    # é¢„å¤„ç†æ‰€æœ‰foldæ•°æ®
    fold_datas = []
    for fold_idx, test_idx in enumerate(test_combos):
        test_idx = np.array(test_idx)
        train_idx = np.setdiff1d(all_indices, test_idx)
        
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]
        
        fold_datas.append((fold_idx, X_train, y_train, X_test, y_test))
    
    # åˆ†é…åˆ°å„GPU
    gpu_fold_batches = {gpu_id: [] for gpu_id in available_gpus}
    for i, fold_data in enumerate(fold_datas):
        gpu_id = available_gpus[i % len(available_gpus)]
        gpu_fold_batches[gpu_id].append(fold_data)
    
    logger.info(f"å¹¶è¡Œç­–ç•¥: {len(available_gpus)}ä¸ªGPU Ã— 8çº¿ç¨‹/GPU")
    logger.info(f"åˆ†é…: {', '.join([f'GPU{g}={len(b)}' for g,b in gpu_fold_batches.items()])}")
    
    # åˆ›å»ºGPUå·¥ä½œå™¨
    workers = [GPUWorker(gpu_id, config) for gpu_id in available_gpus]
    
    start_time = time.time()
    stop_event = threading.Event()
    
    # å¯åŠ¨è¿›åº¦ç›‘æ§
    monitor = threading.Thread(target=progress_monitor, args=(workers, n_folds, start_time, stop_event))
    monitor.start()
    
    logger.info("å¼€å§‹è¿è¡ŒVAE-HyperNetFusionï¼ˆè®ºæ–‡å®ç°ï¼‰...")
    print()
    
    # å¤šçº¿ç¨‹å¹¶è¡Œ
    with ThreadPoolExecutor(max_workers=len(available_gpus)) as executor:
        futures = []
        for worker in workers:
            batch = gpu_fold_batches[worker.gpu_id]
            futures.append(executor.submit(worker.process_batch, batch))
        
        for f in futures:
            f.result()
    
    stop_event.set()
    monitor.join(timeout=2)
    
    elapsed_time = time.time() - start_time
    
    # æ”¶é›†ç»“æœ
    all_results = []
    for worker in workers:
        all_results.extend(worker.results)
    
    valid_results = [r for r in all_results if 'error' not in r]
    error_results = [r for r in all_results if 'error' in r]
    
    all_y_true, all_y_pred = [], []
    for r in valid_results:
        all_y_true.extend(r['y_true'])
        all_y_pred.extend(r['y_pred'])
    
    overall_acc = accuracy_score(all_y_true, all_y_pred) * 100
    
    print()
    logger.info("=" * 70)
    logger.info("[ç»“æœ] VAE-HyperNetFusionï¼ˆä¸¥æ ¼æŒ‰ç…§è®ºæ–‡å®ç°ï¼‰")
    logger.info("=" * 70)
    logger.info(f"  ğŸ¯ æ•´ä½“å‡†ç¡®ç‡: {overall_acc:.2f}%")
    logger.info(f"  âœ… æˆåŠŸfolds: {len(valid_results)}/{n_folds}")
    logger.info(f"  â±ï¸  æ€»ç”¨æ—¶: {elapsed_time:.1f}ç§’")
    logger.info(f"  ğŸš€ é€Ÿåº¦: {n_folds / elapsed_time:.1f} folds/ç§’")
    
    if error_results:
        logger.info(f"  âŒ å¤±è´¥folds: {len(error_results)}")
        for e in error_results[:3]:
            logger.info(f"     é”™è¯¯: {e.get('error', 'unknown')}")
    
    # ä¿å­˜ç»“æœ
    result_file = OUTPUT_DIR / f'15_vae_hypernet_paper_{timestamp}.json'
    
    result_data = {
        'experiment': '15_vae_hypernet_paper',
        'method': 'VAE-HyperNetFusionï¼ˆè®ºæ–‡å®ç°ï¼‰',
        'timestamp': datetime.now().isoformat(),
        'overall_accuracy': overall_acc / 100,
        'elapsed_time': elapsed_time,
        'n_samples': n_samples,
        'n_folds': n_folds,
        'config': config,
        'successful_folds': len(valid_results),
        'failed_folds': len(error_results)
    }
    
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ç»“æœå·²ä¿å­˜: {result_file}")
    logger.info(f"æ—¥å¿—å·²ä¿å­˜: {log_file}")


if __name__ == '__main__':
    main()
