#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
14_hypernet_ensemble.py - çœŸæ­£çš„HyperNetFusioné›†æˆç‰ˆï¼ˆä»¿RFå¤šæ ‘ï¼‰
================================================================
æ ¸å¿ƒæ”¹è¿›ï¼š
1. **å¤šä¸ªHyperNetworké›†æˆ** - åƒRFæœ‰å¤šæ£µæ ‘ï¼Œæˆ‘ä»¬æœ‰å¤šä¸ªè¶…ç½‘ç»œ
2. **å¤šæ ·åŒ–å¢å¼º** - æ¯ä¸ªè¶…ç½‘ç»œç”¨ä¸åŒçš„VAEå¢å¼ºæ•°æ®è®­ç»ƒ
3. **æŠ•ç¥¨æœºåˆ¶** - å¤šä¸ªTargetNetworkæŠ•ç¥¨é¢„æµ‹
4. **å¤§èƒ†å¹¶è¡Œ** - æ¯ä¸ªGPUå¹¶è¡Œ27ä¸ªfold

è¿™æ‰æ˜¯çœŸæ­£ä»¿ç…§RFçš„HyperNetFusionè®¾è®¡ï¼

è¿è¡Œ: python 14_hypernet_ensemble.py
"""

import os
import sys
import json
import time
import logging
import warnings
import threading
from datetime import datetime
from itertools import combinations
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score

warnings.filterwarnings('ignore')

# è·¯å¾„é…ç½®
SCRIPT_DIR = Path(__file__).parent
LOG_DIR = SCRIPT_DIR / 'logs'
OUTPUT_DIR = SCRIPT_DIR / 'output'
LOG_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)

# GPUé…ç½®
GPU_IDS = [0, 1, 2, 3, 4, 5]


# ==================== æ¨¡å‹å®šä¹‰ ====================
class VAE(nn.Module):
    """å˜åˆ†è‡ªç¼–ç å™¨ - ç”¨äºæ•°æ®å¢å¼º"""
    def __init__(self, input_dim, hidden_dim=64, latent_dim=4):
        super(VAE, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim), nn.LeakyReLU(0.2),
            nn.BatchNorm1d(hidden_dim),
            nn.Linear(hidden_dim, hidden_dim // 2), nn.LeakyReLU(0.2)
        )
        self.fc_mu = nn.Linear(hidden_dim // 2, latent_dim)
        self.fc_var = nn.Linear(hidden_dim // 2, latent_dim)
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim // 2), nn.LeakyReLU(0.2),
            nn.Linear(hidden_dim // 2, hidden_dim), nn.LeakyReLU(0.2),
            nn.Linear(hidden_dim, input_dim)
        )
    
    def encode(self, x):
        h = self.encoder(x)
        return self.fc_mu(h), self.fc_var(h)
    
    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        return self.decoder(z)
    
    def forward(self, x):
        mu, log_var = self.encode(x)
        z = self.reparameterize(mu, log_var)
        return self.decode(z), mu, log_var
    
    def sample(self, n_samples, device):
        """ä»æ½œåœ¨ç©ºé—´é‡‡æ ·ç”Ÿæˆæ–°æ•°æ®"""
        z = torch.randn(n_samples, self.fc_mu.out_features).to(device)
        return self.decode(z)


class HyperNetwork(nn.Module):
    """è¶…ç½‘ç»œï¼šä»è®­ç»ƒæ•°æ®ç»Ÿè®¡é‡ç”Ÿæˆç›®æ ‡ç½‘ç»œæƒé‡"""
    def __init__(self, input_dim, stat_dim, hidden_dim, target_hidden, n_classes, dropout=0.3):
        super(HyperNetwork, self).__init__()
        
        self.net = nn.Sequential(
            nn.Linear(stat_dim, hidden_dim), nn.LeakyReLU(0.2), nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim), nn.LeakyReLU(0.2), nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim // 2), nn.LeakyReLU(0.2)
        )
        
        # ç”Ÿæˆä¸¤å±‚å…¨è¿æ¥ç½‘ç»œçš„æƒé‡
        self.gen_w1 = nn.Linear(hidden_dim // 2, input_dim * target_hidden)
        self.gen_b1 = nn.Linear(hidden_dim // 2, target_hidden)
        self.gen_w2 = nn.Linear(hidden_dim // 2, target_hidden * n_classes)
        self.gen_b2 = nn.Linear(hidden_dim // 2, n_classes)
        
        self.input_dim = input_dim
        self.target_hidden = target_hidden
        self.n_classes = n_classes
        
        # æƒé‡åˆå§‹åŒ–
        self._init_weights()
    
    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
    
    def forward(self, stats):
        h = self.net(stats)
        w1 = self.gen_w1(h).view(-1, self.input_dim, self.target_hidden)
        b1 = self.gen_b1(h).view(-1, self.target_hidden)
        w2 = self.gen_w2(h).view(-1, self.target_hidden, self.n_classes)
        b2 = self.gen_b2(h).view(-1, self.n_classes)
        return w1, b1, w2, b2


def target_forward(x, w1, b1, w2, b2):
    """ç›®æ ‡ç½‘ç»œå‰å‘ä¼ æ’­"""
    if w1.dim() == 3:
        h = torch.bmm(x.unsqueeze(1), w1).squeeze(1) + b1
    else:
        h = torch.mm(x, w1) + b1
    h = torch.relu(h)
    if w2.dim() == 3:
        out = torch.bmm(h.unsqueeze(1), w2).squeeze(1) + b2
    else:
        out = torch.mm(h, w2) + b2
    return out


class HyperNetEnsemble:
    """
    HyperNetFusioné›†æˆ - ä»¿ç…§éšæœºæ£®æ—çš„å¤šæ ‘è®¾è®¡
    æ¯ä¸ªè¶…ç½‘ç»œç›¸å½“äºRFä¸­çš„ä¸€æ£µæ ‘
    """
    def __init__(self, n_estimators, input_dim, n_classes, device, config):
        self.n_estimators = n_estimators
        self.input_dim = input_dim
        self.n_classes = n_classes
        self.device = device
        self.config = config
        
        # ç»Ÿè®¡é‡ç»´åº¦
        self.stat_dim = input_dim * 2 + input_dim * input_dim
        
        # åˆ›å»ºå¤šä¸ªè¶…ç½‘ç»œï¼ˆç›¸å½“äºå¤šæ£µæ ‘ï¼‰
        self.hypernets = []
        for i in range(n_estimators):
            # æ¯ä¸ªè¶…ç½‘ç»œç•¥æœ‰ä¸åŒçš„é…ç½®ï¼Œå¢åŠ å¤šæ ·æ€§
            hidden = config['hyper_hidden'] + (i % 3) * 16
            target_h = config['target_hidden'] + (i % 2) * 8
            
            hypernet = HyperNetwork(
                input_dim=input_dim,
                stat_dim=self.stat_dim,
                hidden_dim=hidden,
                target_hidden=target_h,
                n_classes=n_classes,
                dropout=config['dropout'] + (i % 5) * 0.02
            ).to(device)
            self.hypernets.append(hypernet)
        
        # VAEç”¨äºæ•°æ®å¢å¼º
        self.vaes = {}
    
    def compute_stats(self, X_tensor):
        """è®¡ç®—æ•°æ®ç»Ÿè®¡é‡ä½œä¸ºè¶…ç½‘ç»œè¾“å…¥"""
        mean = X_tensor.mean(dim=0)
        std = X_tensor.std(dim=0) + 1e-6
        X_centered = X_tensor - mean
        cov = torch.mm(X_centered.T, X_centered) / (len(X_tensor) - 1 + 1e-6)
        cov_flat = cov.flatten()
        stats = torch.cat([mean, std, cov_flat])
        return stats.unsqueeze(0)
    
    def train_vae_for_class(self, X_cls, cls_label):
        """ä¸ºå•ä¸ªç±»åˆ«è®­ç»ƒVAE"""
        if len(X_cls) < 2:
            return None
        
        vae = VAE(self.input_dim, hidden_dim=64, latent_dim=4).to(self.device)
        optimizer = torch.optim.Adam(vae.parameters(), lr=0.002, weight_decay=1e-5)
        X_tensor = torch.FloatTensor(X_cls).to(self.device)
        
        vae.train()
        for epoch in range(self.config['vae_epochs']):
            optimizer.zero_grad()
            recon, mu, log_var = vae(X_tensor)
            
            # é‡å»ºæŸå¤±
            recon_loss = nn.MSELoss()(recon, X_tensor)
            # KLæ•£åº¦
            kl_loss = -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())
            # æ€»æŸå¤±
            beta = min(1.0, epoch / 50) * 0.1  # æ¸è¿›KLæƒé‡
            loss = recon_loss + beta * kl_loss
            
            loss.backward()
            optimizer.step()
        
        return vae
    
    def generate_augmented_data(self, X, y, estimator_idx):
        """
        ä¸ºç‰¹å®šçš„estimatorç”Ÿæˆå¢å¼ºæ•°æ®
        æ¯ä¸ªestimatorç”¨ä¸åŒçš„å¢å¼ºç­–ç•¥ï¼Œå¢åŠ å¤šæ ·æ€§ï¼ˆç±»ä¼¼RFçš„bootstrapï¼‰
        """
        X_aug_list = [torch.FloatTensor(X).to(self.device)]
        y_aug_list = [torch.LongTensor(y).to(self.device)]
        
        # éšæœºç§å­æ ¹æ®estimator_idxå˜åŒ–ï¼Œç¡®ä¿æ¯ä¸ªè¶…ç½‘ç»œçœ‹åˆ°ä¸åŒçš„å¢å¼ºæ•°æ®
        np.random.seed(42 + estimator_idx)
        
        for cls in np.unique(y):
            X_cls = X[y == cls]
            if len(X_cls) < 2:
                continue
            
            # ä¸ºè¯¥ç±»è®­ç»ƒVAEï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
            vae_key = (cls, estimator_idx % 3)  # å…±äº«éƒ¨åˆ†VAEå‡å°‘è®¡ç®—
            if vae_key not in self.vaes:
                self.vaes[vae_key] = self.train_vae_for_class(X_cls, cls)
            
            vae = self.vaes[vae_key]
            if vae is None:
                continue
            
            vae.eval()
            X_tensor = torch.FloatTensor(X_cls).to(self.device)
            
            with torch.no_grad():
                # 1. é‡å»ºæ’å€¼
                recon = vae(X_tensor)[0]
                # ä¸åŒestimatorç”¨ä¸åŒçš„æ’å€¼æ¯”ä¾‹
                alphas = np.linspace(0.2 + estimator_idx * 0.05, 0.8, self.config['num_interp'])
                for alpha in alphas:
                    aug_data = alpha * X_tensor + (1 - alpha) * recon
                    X_aug_list.append(aug_data)
                    y_aug_list.append(torch.full((len(X_cls),), cls, dtype=torch.long, device=self.device))
                
                # 2. æ½œåœ¨ç©ºé—´é‡‡æ ·
                n_new = max(2, len(X_cls) // 2)
                mu, log_var = vae.encode(X_tensor)
                for _ in range(2):
                    z = vae.reparameterize(mu, log_var)
                    # æ·»åŠ å™ªå£°
                    z = z + torch.randn_like(z) * 0.1 * (estimator_idx % 3 + 1)
                    new_samples = vae.decode(z)
                    X_aug_list.append(new_samples)
                    y_aug_list.append(torch.full((len(X_cls),), cls, dtype=torch.long, device=self.device))
        
        return torch.cat(X_aug_list), torch.cat(y_aug_list)
    
    def train(self, X_train, y_train):
        """è®­ç»ƒæ‰€æœ‰è¶…ç½‘ç»œ"""
        X_tensor = torch.FloatTensor(X_train).to(self.device)
        
        # è®­ç»ƒæ¯ä¸ªè¶…ç½‘ç»œ
        for idx, hypernet in enumerate(self.hypernets):
            # æ¯ä¸ªè¶…ç½‘ç»œç”¨ä¸åŒçš„å¢å¼ºæ•°æ®ï¼ˆç±»ä¼¼RFçš„bootstrapï¼‰
            X_aug, y_aug = self.generate_augmented_data(X_train, y_train, idx)
            
            optimizer = optim.Adam(hypernet.parameters(), 
                                   lr=self.config['lr'] * (0.8 + 0.4 * np.random.random()),
                                   weight_decay=self.config['weight_decay'])
            criterion = nn.CrossEntropyLoss()
            
            # è®¡ç®—ç»Ÿè®¡é‡
            stats = self.compute_stats(X_aug)
            
            # è®­ç»ƒ
            hypernet.train()
            for epoch in range(self.config['epochs']):
                optimizer.zero_grad()
                w1, b1, w2, b2 = hypernet(stats)
                outputs = target_forward(X_aug, w1[0], b1[0], w2[0], b2[0])
                loss = criterion(outputs, y_aug)
                loss.backward()
                optimizer.step()
    
    def predict(self, X_test):
        """é›†æˆé¢„æµ‹ - æŠ•ç¥¨æœºåˆ¶"""
        X_tensor = torch.FloatTensor(X_test).to(self.device)
        
        all_probs = []
        for hypernet in self.hypernets:
            hypernet.eval()
            with torch.no_grad():
                # ä½¿ç”¨æµ‹è¯•æ•°æ®çš„ç»Ÿè®¡é‡
                stats = self.compute_stats(X_tensor)
                w1, b1, w2, b2 = hypernet(stats)
                outputs = target_forward(X_tensor, w1[0], b1[0], w2[0], b2[0])
                probs = torch.softmax(outputs, dim=1)
                all_probs.append(probs)
        
        # å¹³å‡æ¦‚ç‡æŠ•ç¥¨
        avg_probs = torch.stack(all_probs).mean(dim=0)
        return avg_probs.argmax(dim=1).cpu().numpy()


class GPUWorker:
    """GPUå·¥ä½œçº¿ç¨‹ - ä¼˜åŒ–å¹¶è¡Œåº¦"""
    def __init__(self, gpu_id, config):
        self.gpu_id = gpu_id
        self.device = torch.device(f'cuda:{gpu_id}')
        self.config = config
        self.results = []
        self.processed_count = 0
        self.lock = threading.Lock()
        # æ¯ä¸ªGPU 8ä¸ªçº¿ç¨‹ï¼ˆå¤ªå¤šä¼šå†…å­˜äº‰æŠ¢ï¼‰
        self.n_threads = 8
    
    def process_fold(self, fold_data):
        """å¤„ç†å•ä¸ªfold"""
        fold_idx, X_train, y_train, X_test, y_test = fold_data
        
        try:
            input_dim = X_train.shape[1]
            n_classes = len(np.unique(y_train))
            
            # åˆ›å»ºHyperNeté›†æˆ
            ensemble = HyperNetEnsemble(
                n_estimators=self.config['n_estimators'],
                input_dim=input_dim,
                n_classes=n_classes,
                device=self.device,
                config=self.config
            )
            
            # è®­ç»ƒ
            ensemble.train(X_train, y_train)
            
            # é¢„æµ‹
            y_pred = ensemble.predict(X_test)
            
            acc = accuracy_score(y_test, y_pred)
            result = {
                'fold_idx': fold_idx,
                'accuracy': acc,
                'y_true': y_test.tolist(),
                'y_pred': y_pred.tolist(),
                'gpu_id': self.gpu_id
            }
        except Exception as e:
            result = {'fold_idx': fold_idx, 'accuracy': 0.0, 'error': str(e), 'gpu_id': self.gpu_id}
        
        with self.lock:
            self.results.append(result)
            self.processed_count += 1
        
        return result
    
    def process_batch(self, fold_batch):
        """æ‰¹å¤„ç† - 8çº¿ç¨‹å¹¶è¡Œ"""
        print(f"\n[GPU {self.gpu_id}] å¼€å§‹å¤„ç† {len(fold_batch)} ä¸ªfolds...", flush=True)
        with ThreadPoolExecutor(max_workers=self.n_threads) as executor:
            list(executor.map(self.process_fold, fold_batch))


def progress_monitor(workers, total, start_time, stop_event):
    """è¿›åº¦ç›‘æ§"""
    while not stop_event.is_set():
        current = sum(w.processed_count for w in workers)
        elapsed = time.time() - start_time
        
        if elapsed > 0 and current > 0:
            rate = current / elapsed
            eta = (total - current) / rate if rate > 0 else 0
            pct = current / total * 100
            
            all_valid = []
            for w in workers:
                all_valid.extend([r for r in w.results if 'error' not in r])
            
            if all_valid:
                all_true = [item for r in all_valid for item in r['y_true']]
                all_pred = [item for r in all_valid for item in r['y_pred']]
                total_acc = accuracy_score(all_true, all_pred) * 100
            else:
                total_acc = 0.0
            
            bar_len = 30
            filled = int(bar_len * current / total)
            bar = 'â–ˆ' * filled + 'â–‘' * (bar_len - filled)
            
            print(f'\r[{bar}] {current}/{total} ({pct:.1f}%) | {rate:.2f}/s | ETA:{eta:.0f}s | Acc:{total_acc:.2f}%', end='', flush=True)
        
        if current >= total:
            break
        
        time.sleep(0.5)
    print()


def main():
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = LOG_DIR / f'14_hypernet_ensemble_{timestamp}.log'
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler(log_file, encoding='utf-8')
        ]
    )
    logger = logging.getLogger(__name__)
    
    logger.info("=" * 70)
    logger.info("14_hypernet_ensemble.py - çœŸæ­£çš„HyperNetFusioné›†æˆç‰ˆï¼ˆä»¿RFå¤šæ ‘ï¼‰")
    logger.info("=" * 70)
    
    if not torch.cuda.is_available():
        logger.error("CUDAä¸å¯ç”¨!")
        return
    
    n_gpus = torch.cuda.device_count()
    available_gpus = [i for i in GPU_IDS if i < n_gpus]
    logger.info(f"å¯ç”¨GPU: {available_gpus}")
    
    for gpu_id in available_gpus:
        logger.info(f"  GPU {gpu_id}: {torch.cuda.get_device_name(gpu_id)}")
    
    # é…ç½® - ä¼˜åŒ–ç‰ˆï¼ˆå‡å°‘è®¡ç®—é‡ä½†ä¿æŒé›†æˆæ•ˆæœï¼‰
    config = {
        'n_estimators': 5,       # 5ä¸ªè¶…ç½‘ç»œé›†æˆï¼ˆè¶³å¤Ÿäº†ï¼‰
        'hyper_hidden': 96,
        'target_hidden': 32,
        'lr': 0.005,
        'weight_decay': 0.001,
        'dropout': 0.2,
        'epochs': 100,           # å‡å°‘epochs
        'vae_epochs': 50,        # å‡å°‘VAE epochs
        'num_interp': 3
    }
    
    logger.info(f"é…ç½®: {config}")
    logger.info(f"æ ¸å¿ƒæ”¹è¿›: {config['n_estimators']}ä¸ªè¶…ç½‘ç»œé›†æˆï¼ˆä»¿RFå¤šæ ‘ï¼‰")
    
    # åŠ è½½æ•°æ®
    data_path = SCRIPT_DIR / 'data' / 'Data_for_Jinming.csv'
    df = pd.read_csv(data_path)
    feature_cols = ['LAA', 'Glutamate', 'Choline', 'Sarcosine']
    X = df[feature_cols].values.astype(np.float32)
    y_raw = df['Group'].values
    le = LabelEncoder()
    y = le.fit_transform(y_raw)
    
    n_samples = len(X)
    logger.info(f"æ•°æ®: {n_samples} æ ·æœ¬, {X.shape[1]} ç‰¹å¾")
    logger.info(f"ç±»åˆ«: {le.classes_}")
    
    # ç”Ÿæˆæ‰€æœ‰fold
    all_indices = np.arange(n_samples)
    leave_p_out = 2
    test_combos = list(combinations(all_indices, leave_p_out))
    n_folds = len(test_combos)
    
    logger.info(f"Leave-{leave_p_out}-Out: {n_folds} ä¸ª folds")
    
    # é¢„å¤„ç†æ‰€æœ‰foldæ•°æ®
    fold_datas = []
    for fold_idx, test_idx in enumerate(test_combos):
        test_idx = np.array(test_idx)
        train_idx = np.setdiff1d(all_indices, test_idx)
        
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]
        
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        fold_datas.append((fold_idx, X_train_scaled, y_train, X_test_scaled, y_test))
    
    # åˆ†é…åˆ°å„GPU
    gpu_fold_batches = {gpu_id: [] for gpu_id in available_gpus}
    for i, fold_data in enumerate(fold_datas):
        gpu_id = available_gpus[i % len(available_gpus)]
        gpu_fold_batches[gpu_id].append(fold_data)
    
    logger.info(f"å¹¶è¡Œç­–ç•¥: 6ä¸ªGPU Ã— 8çº¿ç¨‹/GPU = 48å¹¶è¡Œ")
    logger.info(f"åˆ†é…: {', '.join([f'GPU{g}={len(b)}' for g,b in gpu_fold_batches.items()])}")
    
    # åˆ›å»ºGPUå·¥ä½œå™¨
    workers = [GPUWorker(gpu_id, config) for gpu_id in available_gpus]
    
    start_time = time.time()
    stop_event = threading.Event()
    
    # å¯åŠ¨è¿›åº¦ç›‘æ§
    monitor = threading.Thread(target=progress_monitor, args=(workers, n_folds, start_time, stop_event))
    monitor.start()
    
    logger.info("å¼€å§‹è¿è¡ŒHyperNetFusioné›†æˆï¼ˆå¤šè¶…ç½‘ç»œ+VAEå¢å¼ºï¼‰...")
    print()
    
    # å¤šçº¿ç¨‹å¹¶è¡Œ
    with ThreadPoolExecutor(max_workers=len(available_gpus)) as executor:
        futures = []
        for worker in workers:
            batch = gpu_fold_batches[worker.gpu_id]
            futures.append(executor.submit(worker.process_batch, batch))
        
        for f in futures:
            f.result()
    
    stop_event.set()
    monitor.join(timeout=2)
    
    elapsed_time = time.time() - start_time
    
    # æ”¶é›†ç»“æœ
    all_results = []
    for worker in workers:
        all_results.extend(worker.results)
    
    valid_results = [r for r in all_results if 'error' not in r]
    error_results = [r for r in all_results if 'error' in r]
    accuracies = [r['accuracy'] for r in valid_results]
    
    mean_acc = np.mean(accuracies) * 100
    std_acc = np.std(accuracies) * 100
    
    all_y_true, all_y_pred = [], []
    for r in valid_results:
        all_y_true.extend(r['y_true'])
        all_y_pred.extend(r['y_pred'])
    
    overall_acc = accuracy_score(all_y_true, all_y_pred) * 100
    
    print()
    logger.info("=" * 70)
    logger.info("[ç»“æœ] VAE-HyperNetFusion é›†æˆç‰ˆï¼ˆä»¿RFå¤šæ ‘ï¼‰")
    logger.info("=" * 70)
    logger.info(f"  ğŸ¯ æ•´ä½“å‡†ç¡®ç‡: {overall_acc:.2f}%")
    logger.info(f"  ğŸ“Š å¹³å‡å‡†ç¡®ç‡: {mean_acc:.2f}% Â± {std_acc:.2f}%")
    logger.info(f"  ğŸŒ² è¶…ç½‘ç»œæ•°é‡: {config['n_estimators']} ä¸ªï¼ˆé›†æˆï¼‰")
    logger.info(f"  âœ… æˆåŠŸfolds: {len(valid_results)}/{n_folds}")
    logger.info(f"  â±ï¸  æ€»ç”¨æ—¶: {elapsed_time:.1f}ç§’")
    logger.info(f"  ğŸš€ é€Ÿåº¦: {n_folds / elapsed_time:.1f} folds/ç§’")
    
    if error_results:
        logger.info(f"  âŒ å¤±è´¥folds: {len(error_results)}")
    
    # ä¿å­˜ç»“æœ
    result_file = OUTPUT_DIR / f'14_hypernet_ensemble_{timestamp}.json'
    
    result_data = {
        'experiment': '14_hypernet_ensemble',
        'method': 'VAE-HyperNetFusioné›†æˆï¼ˆä»¿RFå¤šæ ‘ï¼‰',
        'timestamp': datetime.now().isoformat(),
        'mean_accuracy': mean_acc / 100,
        'std_accuracy': std_acc / 100,
        'overall_accuracy': overall_acc / 100,
        'elapsed_time': elapsed_time,
        'folds_per_second': n_folds / elapsed_time,
        'n_samples': n_samples,
        'n_folds': n_folds,
        'n_gpus': len(available_gpus),
        'n_estimators': config['n_estimators'],
        'config': config,
        'successful_folds': len(valid_results),
        'failed_folds': len(error_results)
    }
    
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ç»“æœå·²ä¿å­˜: {result_file}")
    logger.info(f"æ—¥å¿—å·²ä¿å­˜: {log_file}")


if __name__ == '__main__':
    main()
